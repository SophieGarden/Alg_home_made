{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_home_made(X_test, X_train, y_train, k = 3, f = euclidean_distance):\n",
    "    '''\n",
    "    1 calculate distance wrt all the data points\n",
    "    2 pick the nearest (top K of sorted array) data points \n",
    "    3 return the most frequent labels\n",
    "    \n",
    "    data shape = m * d \n",
    "    k is the # of nearest neighbors \n",
    "    ways of measuring distance can variy, default is euclidean\n",
    "    input are numpy array\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    dist = [[0 for _ in range(len(X_train))] for m in range(len(X_test))]\n",
    "    \n",
    "    for i,x_test in enumerate(X_test):\n",
    "        for j,x_train in enumerate(X_train):\n",
    "            dist[i][j] = f(x_test, x_train)\n",
    "    \n",
    "    index = np.argsort(dist, axis = 1)[:,:k]\n",
    "    label = np.transpose(stats.mode(y_train[index], axis = 1)[0])[0]\n",
    "    \n",
    "    return label\n",
    "    \n",
    "#     index = [0 for _ in range(len(X_test))]\n",
    "#     for i,row in enumerate(dist):\n",
    "#         row = np.array(row)\n",
    "#         index[i] = row.argsort(kind='quicksort')[:k]\n",
    "\n",
    "\n",
    "    \n",
    "#     print(index)\n",
    "#     label = [0 for _ in range(len(X_test))]\n",
    "#     for i,ind in enumerate(index):\n",
    "#         count_label = Counter(y_train[ind])\n",
    "#         label[i] = count_label.most_common(1)[0][0]\n",
    "#     print(y_train[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "    #dist_2 =[(a-b)**2 for a, b in zip(x,y)]\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    dist = np.sqrt(sum(np.square(x-y)))\n",
    "    return dist   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x,y):\n",
    "    '''\n",
    "    When to Use Cosine?\n",
    "Cosine similarity is generally used as a metric for measuring distance when the magnitude of the vectors does not matter. This happens for example when working with text data represented by word counts. We could assume that when a word (e.g. science) occurs more frequent in document 1 than it does in document 2, that document 1 is more related to the topic of science. However, it could also be the case that we are working with documents of uneven lengths (Wikipedia articles for example). Then, science probably occurred more in document 1 just because it was way longer than document 2. Cosine similarity corrects for this.\n",
    "\n",
    "Text data is the most typical example for when to use this metric. However, you might also want to apply cosine similarity for other cases where some properties of the instances make so that the weights might be larger without meaning anything different. Sensor values that were captured in various lengths (in time) between instances could be such an example.\n",
    "'''\n",
    "    return np.dot(x,y)/( np.sqrt(np.dot(x,x)) * np.sqrt(np.dot(y,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991413385403556"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity([ 6.6,6.2] ,[ 9.7,9.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.827007354458868"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance([6.6,6.2] ,[ 9.7,9.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors      [ 6.6  6.2] [ 9.7  9.9]\n",
    "# euclidean    4.82700735446\n",
    "# cosine       0.99914133854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = knn_home_made(X_test, X_train, y_train, 3, euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  7,  2],\n",
       "       [ 0,  4,  7]])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is equal 80.0 %.\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('Accuracy of our model is equal ' + str(round(accuracy, 2)) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sk = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sklearn model is equal 76.67 %.\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_sk)*100\n",
    "print('Accuracy of sklearn model is equal ' + str(round(accuracy, 2)) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from decimal import Decimal\n",
    " \n",
    "# class Similarity():\n",
    " \n",
    "#     \"\"\" Five similarity measures function \"\"\"\n",
    " \n",
    "#     def euclidean_distance(self,x,y):\n",
    " \n",
    "#         \"\"\" return euclidean distance between two lists \"\"\"\n",
    " \n",
    "#         return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    " \n",
    "#     def manhattan_distance(self,x,y):\n",
    " \n",
    "#         \"\"\" return manhattan distance between two lists \"\"\"\n",
    " \n",
    "#         return sum(abs(a-b) for a,b in zip(x,y))\n",
    " \n",
    "#     def minkowski_distance(self,x,y,p_value):\n",
    " \n",
    "#         \"\"\" return minkowski distance between two lists \"\"\"\n",
    " \n",
    "#         return self.nth_root(sum(pow(abs(a-b),p_value) for a,b in zip(x, y)),\n",
    "#            p_value)\n",
    " \n",
    "#     def nth_root(self,value, n_root):\n",
    " \n",
    "#         \"\"\" returns the n_root of an value \"\"\"\n",
    " \n",
    "#         root_value = 1/float(n_root)\n",
    "#         return round (Decimal(value) ** Decimal(root_value),3)\n",
    " \n",
    "#     def cosine_similarity(self,x,y):\n",
    " \n",
    "#         \"\"\" return cosine similarity between two lists \"\"\"\n",
    " \n",
    "#         numerator = sum(a*b for a,b in zip(x,y))\n",
    "#         denominator = self.square_rooted(x)*self.square_rooted(y)\n",
    "#         return round(numerator/float(denominator),3)\n",
    " \n",
    "#     def square_rooted(self,x):\n",
    " \n",
    "#         \"\"\" return 3 rounded square rooted value \"\"\"\n",
    " \n",
    "#         return round(sqrt(sum([a*a for a in x])),3)\n",
    " \n",
    "#     def jaccard_similarity(self,x,y):\n",
    " \n",
    "#     \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    " \n",
    "#         intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "#         union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "#         return intersection_cardinality/float(union_cardinality)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
